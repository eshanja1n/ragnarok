{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import tiktoken\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class LangGraphRAG:\n",
    "    def __init__(self, vectorstore_path=None):\n",
    "        \"\"\"\n",
    "        Initialize the LangGraph RAG system.\n",
    "        \n",
    "        Args:\n",
    "            vectorstore_path (str): Path to existing vectorstore, if None will create new one\n",
    "        \"\"\"\n",
    "        self.vectorstore_path = vectorstore_path or os.path.join(os.getcwd(), \"sklearn_vectorstore.parquet\")\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "        self.llm = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\", temperature=0)\n",
    "        self.vectorstore = None\n",
    "        self.retriever = None\n",
    "        \n",
    "        # Create the prompt template for RAG\n",
    "        self.prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a helpful assistant that answers questions about LangGraph documentation. \n",
    "Use the provided context to answer the user's question accurately and comprehensively.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "- Answer based primarily on the provided context\n",
    "- If the context doesn't contain enough information, say so clearly\n",
    "- Be specific and cite relevant details from the documentation\n",
    "- If you're unsure, acknowledge the uncertainty\"\"\"),\n",
    "            (\"human\", \"{question}\")\n",
    "        ])\n",
    "    \n",
    "    def count_tokens(self, text, model=\"cl100k_base\"):\n",
    "        \"\"\"Count the number of tokens in the text using tiktoken.\"\"\"\n",
    "        encoder = tiktoken.get_encoding(model)\n",
    "        return len(encoder.encode(text))\n",
    "\n",
    "    def bs4_extractor(self, html: str) -> str:\n",
    "        \"\"\"Extract text content from HTML using BeautifulSoup.\"\"\"\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        \n",
    "        # Target the main article content for LangGraph documentation \n",
    "        main_content = soup.find(\"article\", class_=\"md-content__inner\")\n",
    "        \n",
    "        # If found, use that, otherwise fall back to the whole document\n",
    "        content = main_content.get_text() if main_content else soup.text\n",
    "        \n",
    "        # Clean up whitespace\n",
    "        content = re.sub(r\"\\n\\n+\", \"\\n\\n\", content).strip()\n",
    "        \n",
    "        return content\n",
    "\n",
    "    def load_langgraph_docs(self):\n",
    "        \"\"\"Load LangGraph documentation from the official website.\"\"\"\n",
    "        print(\"Loading LangGraph documentation...\")\n",
    "\n",
    "        # Load the documentation \n",
    "        urls = [\n",
    "            \"https://langchain-ai.github.io/langgraph/concepts/\",\n",
    "            \"https://langchain-ai.github.io/langgraph/how-tos/\",\n",
    "            \"https://langchain-ai.github.io/langgraph/tutorials/workflows/\",  \n",
    "            \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\",\n",
    "            \"https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/\",\n",
    "        ] \n",
    "\n",
    "        docs = []\n",
    "        for url in urls:\n",
    "            loader = RecursiveUrlLoader(\n",
    "                url,\n",
    "                max_depth=5,\n",
    "                extractor=self.bs4_extractor,\n",
    "            )\n",
    "\n",
    "            # Load documents using lazy loading (memory efficient)\n",
    "            docs_lazy = loader.lazy_load()\n",
    "\n",
    "            # Load documents and track URLs\n",
    "            for d in docs_lazy:\n",
    "                docs.append(d)\n",
    "\n",
    "        print(f\"Loaded {len(docs)} documents from LangGraph documentation.\")\n",
    "        print(\"\\nLoaded URLs:\")\n",
    "        for i, doc in enumerate(docs):\n",
    "            print(f\"{i+1}. {doc.metadata.get('source', 'Unknown URL')}\")\n",
    "        \n",
    "        # Count total tokens in documents\n",
    "        total_tokens = 0\n",
    "        tokens_per_doc = []\n",
    "        for doc in docs:\n",
    "            doc_tokens = self.count_tokens(doc.page_content)\n",
    "            total_tokens += doc_tokens\n",
    "            tokens_per_doc.append(doc_tokens)\n",
    "        print(f\"Total tokens in loaded documents: {total_tokens}\")\n",
    "        \n",
    "        return docs, tokens_per_doc\n",
    "\n",
    "    def save_docs_to_file(self, documents, filename=\"llms_full.txt\"):\n",
    "        \"\"\"Save the documents to a file.\"\"\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            for i, doc in enumerate(documents):\n",
    "                source = doc.metadata.get('source', 'Unknown URL')\n",
    "                f.write(f\"DOCUMENT {i+1}\\n\")\n",
    "                f.write(f\"SOURCE: {source}\\n\")\n",
    "                f.write(\"CONTENT:\\n\")\n",
    "                f.write(doc.page_content)\n",
    "                f.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "        print(f\"Documents saved to {filename}\")\n",
    "\n",
    "    def split_documents(self, documents):\n",
    "        \"\"\"Split documents into smaller chunks for improved retrieval.\"\"\"\n",
    "        print(\"Splitting documents...\")\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=8000,  \n",
    "            chunk_overlap=500  \n",
    "        )\n",
    "        \n",
    "        split_docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        print(f\"Created {len(split_docs)} chunks from documents.\")\n",
    "        \n",
    "        total_tokens = sum(self.count_tokens(doc.page_content) for doc in split_docs)\n",
    "        print(f\"Total tokens in split documents: {total_tokens}\")\n",
    "        \n",
    "        return split_docs\n",
    "\n",
    "    def create_vectorstore(self, splits):\n",
    "        \"\"\"Create a vector store from document chunks.\"\"\"\n",
    "        print(\"Creating SKLearnVectorStore...\")\n",
    "        \n",
    "        vectorstore = SKLearnVectorStore.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=self.embeddings,\n",
    "            persist_path=self.vectorstore_path,\n",
    "            serializer=\"parquet\",\n",
    "        )\n",
    "        print(\"SKLearnVectorStore created successfully.\")\n",
    "        \n",
    "        vectorstore.persist()\n",
    "        print(f\"SKLearnVectorStore persisted to {self.vectorstore_path}\")\n",
    "\n",
    "        return vectorstore\n",
    "\n",
    "    def load_vectorstore(self):\n",
    "        \"\"\"Load existing vectorstore from disk.\"\"\"\n",
    "        if os.path.exists(self.vectorstore_path):\n",
    "            print(f\"Loading existing vectorstore from {self.vectorstore_path}\")\n",
    "            self.vectorstore = SKLearnVectorStore(\n",
    "                embedding=self.embeddings,\n",
    "                persist_path=self.vectorstore_path,\n",
    "                serializer=\"parquet\"\n",
    "            )\n",
    "            self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Vectorstore not found at {self.vectorstore_path}\")\n",
    "            return False\n",
    "\n",
    "    def setup_rag_system(self, force_rebuild=False):\n",
    "        \"\"\"Set up the complete RAG system.\"\"\"\n",
    "        if not force_rebuild and self.load_vectorstore():\n",
    "            print(\"Using existing vectorstore.\")\n",
    "            return\n",
    "        \n",
    "        print(\"Building new vectorstore...\")\n",
    "        # Load documents\n",
    "        documents, _ = self.load_langgraph_docs()\n",
    "        \n",
    "        # Save documents to file (optional)\n",
    "        self.save_docs_to_file(documents)\n",
    "        \n",
    "        # Split documents\n",
    "        split_docs = self.split_documents(documents)\n",
    "        \n",
    "        # Create vectorstore\n",
    "        self.vectorstore = self.create_vectorstore(split_docs)\n",
    "        self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    def retrieve_context(self, query: str) -> str:\n",
    "        \"\"\"Retrieve relevant context for a query.\"\"\"\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\"RAG system not initialized. Call setup_rag_system() first.\")\n",
    "        \n",
    "        relevant_docs = self.retriever.invoke(query)\n",
    "        print(f\"Retrieved {len(relevant_docs)} relevant documents\")\n",
    "        \n",
    "        # Format context from retrieved documents\n",
    "        formatted_context = \"\\n\\n\".join([\n",
    "            f\"==DOCUMENT {i+1}==\\nSource: {doc.metadata.get('source', 'Unknown')}\\nContent: {doc.page_content}\" \n",
    "            for i, doc in enumerate(relevant_docs)\n",
    "        ])\n",
    "        \n",
    "        return formatted_context\n",
    "\n",
    "    def query(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Query the RAG system and get an answer.\n",
    "        \n",
    "        Args:\n",
    "            question (str): The question to ask about LangGraph\n",
    "            \n",
    "        Returns:\n",
    "            str: The answer based on the retrieved context\n",
    "        \"\"\"\n",
    "        if not self.retriever:\n",
    "            raise ValueError(\"RAG system not initialized. Call setup_rag_system() first.\")\n",
    "        \n",
    "        # Retrieve relevant context\n",
    "        context = self.retrieve_context(question)\n",
    "        \n",
    "        # Generate response using the LLM\n",
    "        messages = self.prompt_template.format_messages(\n",
    "            context=context,\n",
    "            question=question\n",
    "        )\n",
    "        \n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2deceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Example usage of the LangGraph RAG system.\"\"\"\n",
    "    # Initialize the RAG system\n",
    "    rag_system = LangGraphRAG()\n",
    "    \n",
    "    # Set up the system (loads existing vectorstore or creates new one)\n",
    "    rag_system.setup_rag_system()\n",
    "    \n",
    "    # Example queries\n",
    "    questions = [\n",
    "        \"What is LangGraph?\",\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LangGraph RAG System - Example Queries\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nQ: {question}\")\n",
    "        print(\"-\" * 30)\n",
    "        try:\n",
    "            answer = rag_system.query(question)\n",
    "            print(f\"A: {answer}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
